{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import ImgDataset,TgtImgDataset, VideoDataset\n",
    "from sampler import RandomIdentityBatchSampler,RandomTrackletBatchSampler,RandomIdentitySampler\n",
    "from data_manager import Mars,DukeMTMC\n",
    "from utils import GlobalVar\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        # For old pytorch, you may use kaiming_normal.\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, std=0.001)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# Defines the new fc layer and classification layer\n",
    "# |--Linear--|--bn--|--relu--|--Linear--|\n",
    "\n",
    "\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, num_bottleneck=512, linear=True, return_f=False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear:\n",
    "            add_block += [nn.Linear(input_dim, num_bottleneck)]\n",
    "        else:\n",
    "            num_bottleneck = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(num_bottleneck)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate > 0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(num_bottleneck, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return x, f\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self,num_parts):\n",
    "\n",
    "        super(FeatureExtractor,self).__init__()\n",
    "        self.num_parts = num_parts\n",
    "        resnet50 = models.resnet50(pretrained=True)\n",
    "        self.base = nn.Sequential(*list(resnet50.children())[:-2])\n",
    "        self.pcb_pool = nn.AdaptiveAvgPool2d((num_parts,1))\n",
    "        self.half_pool = nn.AdaptiveAvgPool2d((2,1))\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.base(x)\n",
    "\n",
    "        glob = self.global_pool(x)\n",
    "        glob = glob.view(glob.size(0),glob.size(1),glob.size(2))\n",
    "\n",
    "        if self.num_parts > 0:\n",
    "        \n",
    "            halfs = self.half_pool(x)\n",
    "            halfs = halfs.view(halfs.size(0),halfs.size(1),halfs.size(2))\n",
    "            \n",
    "            stripes = self.pcb_pool(x)\n",
    "            stripes = stripes.view(stripes.size(0),stripes.size(1),stripes.size(2))\n",
    "            \n",
    "            features = torch.cat([glob,halfs,stripes],dim=2)\n",
    "\n",
    "        else:\n",
    "            features = glob\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(6).cuda(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,3,256,128).cuda(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = feature_extractor(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrcReidModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(SrcReidModel,self).__init__()\n",
    "        self.num_parts = feature_extractor.num_parts        \n",
    "        self.classifier1 = ClassBlock(2048,class_num=num_classes,num_bottleneck=512,droprate=0.5)\n",
    "        if self.num_parts > 0:\n",
    "            for i in range(self.num_parts+2): \n",
    "                setattr(self,'classifier'+str(i+2),ClassBlock(2048,class_num=num_classes,num_bottleneck=256,droprate=0.5))\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        y = []\n",
    "        for i in range(features.size(2)):\n",
    "            y.append(getattr(self,'classifier'+str(i+1))(x[:,:,i]))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4,2048,1)\n",
    "b = torch.randn(4,2048,6)\n",
    "c = torch.cat([a,b],dim=2)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_reid_model = SrcReidModel(615).cuda(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_extractor(x)\n",
    "y = src_reid_model(features)\n",
    "print(len(y))\n",
    "print(y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TgtPartModel(nn.Module):\n",
    "    def __init__(self,num_parts):\n",
    "        super(TgtPartModel,self).__init__()\n",
    "\n",
    "        self.num_parts = num_parts\n",
    "\n",
    "        if self.num_parts > 0:\n",
    "            for i in range(self.num_parts): \n",
    "                setattr(self,'classifier'+str(i+1),ClassBlock(2048,class_num=self.num_parts,num_bottleneck=256,droprate=0.5))\n",
    "    def forward(self,x):\n",
    "        \n",
    "        y = []\n",
    "        for i in range(3,x.size(2)):\n",
    "            y.append(getattr(self,'classifier'+str(i-2))(x[:,:,i]))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_part_model = TgtPartModel(feature_extractor.num_parts).cuda(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tgt_part_model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import TripletMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTripletLoss(nn.Module):\n",
    "    \"\"\"Triplet loss with hard positive/negative mining.\n",
    "    \n",
    "    Reference:\n",
    "        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
    "    \n",
    "    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n",
    "    \n",
    "    Args:\n",
    "        margin (float, optional): margin for triplet. Default is 0.3.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin=0.3):\n",
    "        super(ModifiedTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
    " \n",
    "    def forward(self,src_input,tgt_input,tracklet_label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n",
    "            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n",
    "        \"\"\"\n",
    "        if not isinstance(tracklet_label,torch.Tensor):\n",
    "            tracklet_label = torch.Tensor(tracklet_label)\n",
    "        if len(tracklet_label.shape) > 1:\n",
    "            tracklet_label = torch.flatten(tracklet_label)\n",
    "        m = src_input.size(0)\n",
    "        n = tgt_input.size(0)\n",
    "\n",
    "        tgt_distmat = torch.pow(tgt_input,2).sum(dim=1,keepdim=True).expand(n,n) + \\\n",
    "                      torch.pow(tgt_input,2).sum(dim=1,keepdim=True).expand(n,n).t()\n",
    "        tgt_distmat.addmm_(1,-2,tgt_input,tgt_input.t())\n",
    "        tgt_distmat = tgt_distmat.clamp(min=1e-12).sqrt() \n",
    "        tgt_src_dismat = torch.pow(tgt_input,2).sum(dim=1,keepdim=True).expand(n,m) + \\\n",
    "                         torch.pow(src_input,2).sum(dim=1,keepdim=True).expand(m,n).t()\n",
    "        tgt_src_dismat.addmm_(1,-2,tgt_input,src_input.t())\n",
    "        tgt_src_dismat = tgt_src_dismat.clamp(min=1e-12).sqrt() \n",
    "\n",
    "        mask = tracklet_label.expand(n,n).eq(tracklet_label.expand(n,n).t())\n",
    "        dist_ap,dist_an = [], []\n",
    "        for i in range(n):\n",
    "            dist_ap.append(tgt_distmat[i][mask[i]].max().unsqueeze(0))\n",
    "            dist_an.append(tgt_src_dismat[i].min().unsqueeze(0))\n",
    "        dist_ap = torch.cat(dist_ap)\n",
    "        dist_an = torch.cat(dist_an)\n",
    "        \n",
    "        # Compute ranking hinge loss\n",
    "        y = torch.ones_like(dist_an)\n",
    "        return self.ranking_loss(dist_an, dist_ap, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"Triplet loss with hard positive/negative mining.\n",
    "    \n",
    "    Reference:\n",
    "        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
    "    \n",
    "    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n",
    "    \n",
    "    Args:\n",
    "        margin (float, optional): margin for triplet. Default is 0.3.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin=0.3,global_feat, labels):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
    " \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n",
    "            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n",
    "        \"\"\"\n",
    "        n = inputs.size(0)\n",
    "        \n",
    "        # Compute pairwise distance, replace by the official when merged\n",
    "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
    "        dist = dist + dist.t()\n",
    "        dist.addmm_(1, -2, inputs, inputs.t())\n",
    "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "        \n",
    "        # For each anchor, find the hardest positive and negative\n",
    "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "        dist_ap, dist_an = [], []\n",
    "        for i in range(n):\n",
    "            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n",
    "            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n",
    "        dist_ap = torch.cat(dist_ap)\n",
    "        dist_an = torch.cat(dist_an)\n",
    "        \n",
    "        # Compute ranking hinge loss\n",
    "        y = torch.ones_like(dist_an)\n",
    "        return self.ranking_loss(dist_an, dist_ap, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "modified_triplet_loss = ModifiedTripletLoss()\n",
    "a = torch.randn(4,2048,9)\n",
    "b = torch.randn(4,2048,9)\n",
    "\n",
    "loss = modified_triplet_loss(a[:,:,0],b[:,:,0],[2,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,4)\n",
    "b = torch.flatten(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_var = GlobalVar()\n",
    "mars = Mars()\n",
    "dukemtmc = DukeMTMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-59-3b8ea5c3ff1f>, line 23)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-3b8ea5c3ff1f>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    num_workers=4)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((256,128)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]\n",
    ")\n",
    "train_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((256,128)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]\n",
    ")\n",
    "tgt_train_dataset = VideoDataset(mars.train,train_transform,4)\n",
    "tgt_train_loader = DataLoader(tgt_train_dataset, \\\n",
    "                   batch_sampler = RandomTrackletBatchSampler(dataset=mars.train,glob_var=glob_var),\n",
    "                   num_workers = 0,\n",
    "                   pin_memory = False,\n",
    "                   collate_fn=tgt_collate_fn,\n",
    "                   num_workers=4)\n",
    "\n",
    "src_train_dataset = ImgDataset(dukemtmc.train,train_transform)\n",
    "tgt_img_dataset = TgtImgDataset(mars.gallery,train_transform)\n",
    "src_reid_loader = DataLoader(dataset = src_train_dataset, batch_size = 64,shuffle=False,num_workers=4,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_var.tgt_batch_size = 16\n",
    "tgt_train_iter = iter(tgt_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_reid_iter = iter(src_reid_loader)\n",
    "print(next(src_reid_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars.train.loc[:,'pid'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(tgt_train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tgt_collate_fn(batch):\n",
    "    imgs = []\n",
    "    pids = []\n",
    "    camids = []\n",
    "    tracklets = []\n",
    "    paths = []\n",
    "    for img,pid,camid,path,tracklet in batch:\n",
    "        imgs += [img.unsqueeze(dim=0)]\n",
    "        pids += pid\n",
    "        camids += camid\n",
    "        tracklets += tracklet\n",
    "        paths += path\n",
    "    imgs = torch.cat(imgs,dim=0)\n",
    "    b,t,c,h,w = imgs.shape\n",
    "    imgs = imgs.view(b*t,c,h,w)\n",
    "    return imgs,torch.IntTensor(pids),torch.IntTensor(camids),paths,torch.IntTensor(tracklets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(dataloader, feature_extractor):\n",
    "    features = []\n",
    "    pids = []\n",
    "    camids = []\n",
    "    tracklets = []\n",
    "    paths = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,batch in enumerate(dataloader):\n",
    "            imgs = batch[0].cuda(3)\n",
    "            pid = batch[1]\n",
    "            camid = batch[2]\n",
    "            path = list(batch[3])\n",
    "            if len(batch) > 4:\n",
    "                tracklet = batch[4]\n",
    "                tracklets.append(tracklet)\n",
    "\n",
    "            feature = feature_extractor(imgs)\n",
    "\n",
    "            features += [feature[:,:,0].cpu()] \n",
    "            pids += [pid]\n",
    "            camids += [camid]\n",
    "            paths += path\n",
    "            print(batch_idx)\n",
    "        features = torch.cat(features,dim=0)\n",
    "        pids = torch.cat(pids,dim=0).numpy()\n",
    "        if len(tracklets) > 0:\n",
    "            tracklets = torch.cat(tracklets,dim=0).numpy()\n",
    "    return features,pids,camids,paths,tracklets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4,3)\n",
    "b = torch.randn(3,3)\n",
    "c = torch.cat([a,b],dim=0)\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2,3)\n",
    "b = list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distmat(a,b):\n",
    "    m = a.size(0)\n",
    "    n = b.size(0)\n",
    "    distmat = torch.pow(a,2).sum(dim=1,keepdim=True).expand(m,n) + \\\n",
    "                         torch.pow(b,2).sum(dim=1,keepdim=True).expand(n,m).t()\n",
    "    distmat.addmm_(1,-2,a,b.t())\n",
    "    distmat = distmat.clamp(min=1e-12).sqrt() \n",
    "    return distmat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distmat = compute_distmat(result[0],result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_var.feature_extractor = feature_extractor\n",
    "glob_var.save_path = './Logs'\n",
    "glob_var.src_data = DukeMTMC()\n",
    "glob_var.tgt_data = Mars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage1Var():\n",
    "    def init():\n",
    "        reid_batchsize = 64\n",
    "        part_batchsize = 64\n",
    "        num_workers = 4\n",
    "        use_gpu = True\n",
    "        transfrom = T.Compose(\n",
    "                    [\n",
    "                        T.Resize((256,128)),\n",
    "                        T.RandomHorizontalFlip(),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "glob_var.stage1 = Stage1Var()\n",
    "glob_var.stage1.sampler = RandomIdentitySampler(glob_var.src_data.train,glob_var.seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainStage1(object):\n",
    "    def __init__(self,glob_var):\n",
    "        self.glob_var = glob_var\n",
    "        self.feature_extractor = glob_var.feature_extractor\n",
    "        self.save_freq = 0\n",
    "        self.\n",
    "\n",
    "    def get_dataloader(self,glob_var):\n",
    "        src_loader = DataLoader(ImgDataset(glob_var.src_data.train,glob_var.stage1.transform),\n",
    "                               batch_size = glob_var.stage1.reid_datasize,\n",
    "                               num_workers=glob_var.stage1.num_workers,\n",
    "                               sampler=glob_var.stage1.smapler,\n",
    "                               drop_last=True,\n",
    "                               pin_memory=False\n",
    "                               )\n",
    "        tgt_loader = DataLoader(TgtImgDataset(glob_var.tgt_data.train,glob_var.satge1.transform),\n",
    "                                    )\n",
    "        \n",
    "    def train(self):\n",
    "        pass\n",
    "            \n",
    "def TrainStage2(object):\n",
    "    def __init__(self,glob_var):\n",
    "        self.glob_var = glob_var\n",
    "    def get_dataloader(self,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('torchreid': conda)",
   "language": "python",
   "name": "python37664bittorchreidconda95b811415b44457485f97a87d0668b7f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}