{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import ImgDataset,TgtImgDataset, VideoDataset\n",
    "from sampler import RandomIdentityBatchSampler,RandomTrackletBatchSampler,RandomIdentitySampler\n",
    "from data_manager import Mars,DukeMTMC\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from model import FeatureExtractor,SrcReidModel,TgtPartModel,ModifiedTripletLoss,TripletLoss\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(dataloader, feature_extractor):\n",
    "    features = []\n",
    "    pids = []\n",
    "    camids = []\n",
    "    tracklets = []\n",
    "    paths = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,batch in enumerate(dataloader):\n",
    "            imgs = batch[0].cuda(3)\n",
    "            pid = batch[1]\n",
    "            camid = batch[2]\n",
    "            path = list(batch[3])\n",
    "            if len(batch) > 4:\n",
    "                tracklet = batch[4]\n",
    "                tracklets.append(tracklet)\n",
    "\n",
    "            feature = feature_extractor(imgs)\n",
    "\n",
    "            features += [feature[:,:,0].cpu()] \n",
    "            pids += [pid]\n",
    "            camids += [camid]\n",
    "            paths += path\n",
    "            print(batch_idx)\n",
    "        features = torch.cat(features,dim=0)\n",
    "        pids = torch.cat(pids,dim=0).numpy()\n",
    "        if len(tracklets) > 0:\n",
    "            tracklets = torch.cat(tracklets,dim=0).numpy()\n",
    "    return features,pids,camids,paths,tracklets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distmat(a,b):\n",
    "    m = a.size(0)\n",
    "    n = b.size(0)\n",
    "    distmat = torch.pow(a,2).sum(dim=1,keepdim=True).expand(m,n) + \\\n",
    "                         torch.pow(b,2).sum(dim=1,keepdim=True).expand(n,m).t()\n",
    "    distmat.addmm_(1,-2,a,b.t())\n",
    "    distmat = distmat.clamp(min=1e-12).sqrt() \n",
    "    return distmat.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "    \"\"\"Cross entropy loss with label smoothing regularizer.\n",
    "\n",
    "    Reference:\n",
    "    Szegedy et al. Rethinking the Inception Architecture for Computer Vision. CVPR 2016.\n",
    "    Equation: y = (1 - epsilon) * y + epsilon / K.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        epsilon (float): weight.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, epsilon=0.1, use_gpu=True):\n",
    "        super(CrossEntropyLabelSmooth, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.use_gpu = use_gpu\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: prediction matrix (before softmax) with shape (batch_size, num_classes)\n",
    "            targets: ground truth labels with shape (num_classes)\n",
    "        \"\"\"\n",
    "        log_probs = self.logsoftmax(inputs)\n",
    "        targets = torch.zeros(log_probs.size()).scatter_(1, targets.unsqueeze(1).data.cpu(), 1)\n",
    "        if self.use_gpu: targets = targets.cuda()\n",
    "        targets = Variable(targets, requires_grad=False)\n",
    "        targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "        loss = (- targets * log_probs).mean(0).sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GlobalVar(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self._tgt_batch_size = 8\n",
    "        self.seq_len = 4\n",
    "        self.batch_size_sum = 64\n",
    "        self.num_parts = 6\n",
    "        self.gpu_ids = [3]\n",
    "        self.feature_extractor = FeatureExtractor(self.num_parts)\n",
    "        if len(self.gpu_ids > 0):\n",
    "            self.use_gpu = True\n",
    "            torch.cuda.set_device(self.gpu_ids)\n",
    "            self.feature_extractor = nn.DataParallel(self.feature_extractor,self.gpu_ids)\n",
    "        else:\n",
    "            self.use_gpu = False\n",
    "\n",
    "        self.save_path = './Logs'\n",
    "        self.src_data = DukeMTMC()\n",
    "        self.tgt_data = Mars()\n",
    "\n",
    "        self.train_transfrom = T.Compose(\n",
    "            [\n",
    "                T.Resize((256,128)),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = T.Compose(\n",
    "            [\n",
    "                T.Resize((256,128)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def tgt_batch_size(self):\n",
    "        return self._tgt_batch_size\n",
    "\n",
    "    @tgt_batch_size.setter\n",
    "    def tgt_batch_size(self, value):\n",
    "\n",
    "        if value*self.seq_len > self.batch_size_sum:\n",
    "            self._tgt_batch_size = (\n",
    "                self.batch_size_sum // self.seq_len)*self.seq_len\n",
    "        elif value < 0:\n",
    "            self._tgt_batch_size = 0\n",
    "        else:\n",
    "            self._tgt_batch_size = value\n",
    "\n",
    "    @property\n",
    "    def src_batch_size(self):\n",
    "        return self.batch_size_sum - self._tgt_batch_size*self.seq_len\n",
    "\n",
    "    def step(self):\n",
    "        pass\n",
    "\n",
    "    def set_global_var(self,name,value):\n",
    "        setattr(self,name,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_var = GlobalVar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\n",
    "       \n",
    "       Code imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainStage1(object):\n",
    "    def __init__(self,glob_var,opt):\n",
    "\n",
    "        self.glob_var           = glob_var\n",
    "        self.save_name          = '_stage1_'\n",
    "\n",
    "        # 数据加载参数\n",
    "        self.reid_train_data    = self.glob_var.src_data.train\n",
    "        self.src_batchsize      = 64\n",
    "        self.tgt_batchsize      = 64\n",
    "        self.num_workers        = 4\n",
    "        self.reid_sampler       = RandomIdentitySampler(glob_var.src_data.train,glob_var.seq_len)\n",
    "\n",
    "        # 模型参数\n",
    "        self.feature_extractor  = self.glob_var.feature_extractor\n",
    "        self.num_classes        = len(set(self.reid_train_data['pid']))\n",
    "        self.num_parts          = self.feature_extractor.num_parts\n",
    "\n",
    "        # 优化器参数\n",
    "        self.src_extract_lr     = 0.005\n",
    "        self.src_model_lr       = 0.05\n",
    "        self.src_weight_decay   = 5e-04\n",
    "        self.src_step_size      = 40\n",
    "        self.src_gamma          = 0.1\n",
    "        self.tgt_extract_lr     = 0.005\n",
    "        self.tgt_model_lr       = 0.05\n",
    "        self.tgt_weight_decay   = 5e-04\n",
    "        self.tgt_step_size      = 40\n",
    "        self.tgt_gamma          = 0.1\n",
    "        self.src_optim          = optim.Adam\n",
    "        self.tgt_optim          = optim.Adam\n",
    "\n",
    "        # Loss函数\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.triplet_loss       = TripletLoss()\n",
    "\n",
    "        # 训练参数\n",
    "        self.max_epoch          = 200\n",
    "        self.use_triplet_loss   = True\n",
    "        self.tgt_labels         = [torch.IntTensor([i]*self.tgt_batchsize) for i in range(self.num_parts)]\n",
    "\n",
    "        if self.glob_var.use_gpu:\n",
    "            for i in range(len(self.tgt_labels)):\n",
    "                self.tgt_labels[i] = self.tgt_labels[i].cuda()\n",
    "        \n",
    "    def get_dataloader(self):\n",
    "\n",
    "        self.src_loader = DataLoader(ImgDataset(self.reid_train_data,self.glob_var.train_transform),\n",
    "                               batch_size = self.src_datasize,\n",
    "                               shuffle = True,\n",
    "                               num_workers = self.num_workers,\n",
    "                               drop_last = True,\n",
    "                               pin_memory = False,\n",
    "                               sampler = self.reid_sampler)\n",
    "\n",
    "        self.tgt_loader = DataLoader(VideoDataset(self.glob_var.tgt_data.train,self.glob_var.train_transform,self.glob_var.seq_len),\n",
    "                               batch_size = self.tgt_batchsize//self.glob_var.seq_len,\n",
    "                               shuffle = True,\n",
    "                               num_workers = self.num_workers,\n",
    "                               drop_last = True \n",
    "                               pin_memory = False)\n",
    "\n",
    "    def get_model(self):\n",
    "\n",
    "        self.src_model = SrcReidModel(self.num_classes)\n",
    "        self.tgt_model = TgtPartModel(self.num_parts)\n",
    "\n",
    "        if self.glob_var.use_gpu:\n",
    "            self.src_model = nn.DataParallel(self.src_model,self.glob_var.gpu_ids)\n",
    "            self.tgt_model = nn.DataParallel(self.tgt_model,self.glob_var.gpu_ids)\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "\n",
    "        self.src_optimizer = self.src_optim(\n",
    "            [{'params':self.feature_extractor.parameters(),'lr':self.src_extract_lr},\n",
    "            {'params':self.src_model.parameters(),'lr':self.src_model_lr}],\n",
    "            weight_decay = self.src_weight_decay\n",
    "        )\n",
    "        \n",
    "        self.tgt_optimizer = self.tgt_optim(\n",
    "            [{'params':self.feature_extractor.parameters(),'lr':self.src_extract_lr},\n",
    "            {'params':self.tgt_model.parameters(),'lr':self.tgt_model_lr}],\n",
    "            weight_decay = self.tgt_weight_decay\n",
    "        )\n",
    "\n",
    "        self.src_lr_scheduler = lr_scheduler(self.src_optimizer,step_size=self.src_step_size,gamma=self.src_gamma)\n",
    "        self.tgt_lr_scheduler = lr_scheduler(self.tgt_optimizer,step_size=self.tgt_step_size,gamma=self.tgt_gamma)\n",
    "\n",
    "    def train_tgt_one_batch(self,batch):\n",
    "        imgs = batch[0]\n",
    "        if self.glob_var.use_gpu:\n",
    "            imgs = imgs.cuda()\n",
    "        features = self.feature_extractor(imgs)\n",
    "        predicts = self.tgt_model(features)\n",
    "\n",
    "        loss = self.cross_entropy_loss(predicts[0],self.tgt_labels[0])\n",
    "        for i in range(len(predicts)-1):\n",
    "            loss += self.cross_entropy_loss(predicts[i+1],self.tgt_labels[i+1])\n",
    "\n",
    "        tgt_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tgt_optimizer.step()\n",
    "        return loss\n",
    "        \n",
    "    def train_src_one_batch(self,batch):\n",
    "        imgs = batch[0]\n",
    "        labels = batch[1]\n",
    "        if self.glob_var.use_gpu:\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        features = self.feature_extractor(imgs)\n",
    "        predicts = self.src_model(features)\n",
    "\n",
    "        cross_loss = self.cross_entropy_loss(predicts[0],labels)\n",
    "        for i in range(len(predicts) - 1):\n",
    "            cross_loss += self.cross_entropy_loss(predicts[i+1],labels)\n",
    "        loss = cross_loss\n",
    "\n",
    "        if self.use_triplet_loss:\n",
    "            tri_loss = self.triplet_loss(featuers[:,:,0],labels)\n",
    "            loss += tri_loss\n",
    "        src_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        src_optimizer.step()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def _init_train(self):\n",
    "        self.get_dataloader()\n",
    "        self.get_model()\n",
    "        self.get_optimizer()\n",
    "\n",
    "    def train(self):\n",
    "        self._init_train()\n",
    "        for epoch in range(self.max_epoch):\n",
    "            for src_batch in self.src_loader:\n",
    "                src_loss = self.train_src_one_batch(src_batch)\n",
    "                \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sun Mar 29 08:13:51 2020       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n| 78%   87C    P2   223W / 250W |   8365MiB / 11172MiB |     79%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\n| 68%   83C    P2    83W / 250W |   8961MiB / 11172MiB |     99%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n| 28%   49C    P2    58W / 250W |    617MiB / 11172MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\n| 75%   85C    P2   140W / 250W |   8379MiB / 11172MiB |     59%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n"
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_labels = [torch.IntTensor([i]*64) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tgt_labels)):\n",
    "    if True:\n",
    "        tgt_labels[i] = tgt_labels[i].cuda()\n",
    "    tgt_labels[i][:,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32), tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=torch.int32), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=torch.int32), tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=torch.int32), tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=torch.int32)]\n"
    }
   ],
   "source": [
    "a = torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainStage2(object):\n",
    "    def __init__(self,glob_var):\n",
    "        self.glob_var = glob_var\n",
    "    def get_dataloader(self,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('torchreid': conda)",
   "language": "python",
   "name": "python37664bittorchreidconda95b811415b44457485f97a87d0668b7f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}